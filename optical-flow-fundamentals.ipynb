{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c50882-c797-4ba5-a53f-2b35dbd3c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a0c52-78ef-40bf-82ef-c42069789fe5",
   "metadata": {},
   "source": [
    "#### フレームレートの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72099d14-c8be-4e82-a911-de6a045b89ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "フレームレート: 30.0 fps\n"
     ]
    }
   ],
   "source": [
    "# Webカメラを起動\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# フレームレートを取得\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"フレームレート: {fps} fps\")\n",
    "\n",
    "# カメラを解放\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833a0db-4ffb-4a1b-9c11-532d943b7a18",
   "metadata": {},
   "source": [
    "### Pyramidal Lucas-kanade法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e91319-6701-4e72-bdea-fe3c1e7722b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴点検出するためのパラメータ\n",
    "# maxCorners=10: 検出する最大のコーナー（特徴点）の数を指定する。この場合、最大で10個の特徴点を検出する。\n",
    "# qualityLevel=0.3: 特徴点の品質を決定するためのパラメータである。0から1の範囲で、値が小さいほど多くの特徴点が検出されるが、品質が低くなる可能性がある。\n",
    "# minDistance=7: 検出された特徴点の間の最小距離を指定する。この距離より近い特徴点は無視される。これにより、重複した特徴点を避けることができる。\n",
    "# blockSize=7: コーナー検出に使用する近傍のサイズを指定する。これは、特徴点の計算に使用されるピクセルのブロックのサイズである。\n",
    "\n",
    "corner_track_params = dict(maxCorners=10, qualityLevel=0.3, minDistance=7, blockSize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c25b51b-fdfc-4bf7-9029-5ca3d0ba9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucas kanade法のパラメータ\n",
    "# winSize = (200, 200): ウィンドウのサイズを指定する。ウィンドウは、特徴点の周囲の領域。その領域内で動きを推定する。(200, 200)は、ウィンドウの幅と高さをピクセル単位で示しており、200ピクセル×200ピクセルの領域が使用される。\n",
    "# 大きなウィンドウサイズは、小さい動きを見落とす可能性が高く、一方、小さいウィンドウサイズは、大きい動きを見落とす可能性が高い。つまりトレードオフ。\n",
    "# maxLevel = 2:\n",
    "# このパラメータは、画像の解像度を指定する。https://en.wikipedia.org/wiki/Pyramid_(image_processing)を参考に。\n",
    "# criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03):\n",
    "# このパラメータは、オプティカルフローの計算を終了するための条件を指定する。\n",
    "# cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT: 終了条件のタイプを指定する。ここでは、2つの条件を組み合わせている。\n",
    "# cv2.TERM_CRITERIA_EPS: 精度が指定された閾値以下になると終了する。（精度）\n",
    "# cv2.TERM_CRITERIA_COUNT: 最大反復回数に達すると終了する。（スピード）\n",
    "\n",
    "lk_params = dict(winSize = (200,200), maxLevel = 2, criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10,0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d54cd1d-2d7b-4ed9-bcbb-2f9018d36ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCのカメラを起動\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# PCのカメラを起動した際の最初のフレームを取得する\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# グレースケール画像を取得する（これを前のフレームとして参照する）\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 特徴点を取得する（Shi-Tomasiコーナー検出）\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask = None, **corner_track_params)\n",
    "\n",
    "# 後で描画するために、前のフレームのマスクを作成する（480, 640, 3)\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # 現在のフレームを取得する\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # グレースケールを取得する\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # グレースケールフレームでオプティカルフローを計算する\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n",
    "    \n",
    "    # 返されたステータス配列を使用する(10, 1, 2)\n",
    "    # ステータス出力ベクトル（符号なし文字型）；ベクトルの各要素は、対応する特徴のフローが見つかった場合は1に設定され、そうでない場合は0に設定される。\n",
    "    good_new = nextPts[status==1]\n",
    "    good_prev = prevPts[status==1]\n",
    "    \n",
    "    for i, (new, prev) in enumerate(zip(good_new, good_prev)):\n",
    "        \n",
    "        x_new, y_new = new.ravel()\n",
    "        x_prev, y_prev = prev.ravel()\n",
    "        \n",
    "        # 最初のフレームから作成したマスクを使用して線を描く\n",
    "        mask = cv2.line(mask, (x_new, y_new), (x_prev, y_prev), (0, 255, 0), 3)\n",
    "        \n",
    "        # 特徴点に赤い円を描く\n",
    "        frame = cv2.circle(frame, (x_new, y_new), 8, (0, 0, 255), -1)\n",
    "    \n",
    "    # 描いた線を含むマスクと画像を表示する\n",
    "    img = cv2.add(frame, mask)\n",
    "    cv2.imshow('frame', img)\n",
    "\n",
    "    # Escで終了する\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "    # 前のフレームと前のポイントを更新する\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378efc07-d24d-4499-9f90-f2c740dad948",
   "metadata": {},
   "source": [
    "### Farneback法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a20a782-7e83-4dcb-a8e3-31dc28713f64",
   "metadata": {},
   "source": [
    "#### calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow\n",
    "この関数は、Gunnar Farnebackのアルゴリズムを使用して密なオプティカルフローを計算します。以下は、関数のパラメータとその意味です：\n",
    "\n",
    "- prev: 最初の8ビット単一チャンネル入力画像。\n",
    "- next: prevと同じサイズおよび同じタイプの2番目の入力画像。\n",
    "- flow: prevと同じサイズで、タイプがCV_32FC2の計算されたフロー画像。\n",
    "- pyr_scale: 各画像のピラミッドを構築するための画像スケールを指定するパラメータ（1未満）。pyr_scale=0.5は、古典的なピラミッドを意味し、次の層は前の層の2倍小さくなります。\n",
    "- levels: 初期画像を含むピラミッドの層数。levels=1の場合、追加の層は作成されず、元の画像のみが使用されます。\n",
    "- winsize: 平均化ウィンドウのサイズ。大きい値は、画像のノイズに対するアルゴリズムの堅牢性を高め、高速な動きの検出の機会を増やしますが、よりぼやけた運動場を生じます。\n",
    "- iterations: 各ピラミッドレベルでのアルゴリズムの反復回数。\n",
    "- poly_n: 各ピクセルでの多項式展開を見つけるために使用されるピクセル近傍のサイズ。大きい値は、画像がより滑らかな表面で近似されることを意味し、より堅牢なアルゴリズムとよりぼやけた運動場を生じます。通常、poly_n=5または7。\n",
    "- poly_sigma: 多項式展開の基盤として使用される導関数の平滑化に使用されるガウス分布の標準偏差。poly_n=5の場合、poly_sigma=1.1を設定できます。poly_n=7の場合、適切な値はpoly_sigma=1.5です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c2c91a-d857-4194-a95c-53799e26b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# フレームをキャプチャする\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "# 最初のフレームのグレースケール画像を取得し、HSVカラーでマスクを作成する\n",
    "prvsImg = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv_mask = np.zeros_like(frame1)\n",
    "hsv_mask[:,:,1] = 255\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    nextImg = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(prvsImg,nextImg, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    \n",
    "    # 移動の角度に基づいてチャンネルを色付けする\n",
    "    mag, ang = cv2.cartToPolar(flow[:,:,0], flow[:,:,1],angleInDegrees=True)\n",
    "    hsv_mask[:,:,0] = ang/2\n",
    "    hsv_mask[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    # cvのimshowで表示するためにBGRに変換する\n",
    "    bgr = cv2.cvtColor(hsv_mask,cv2.COLOR_HSV2BGR)\n",
    "    cv2.imshow('frame2',bgr)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    # ループのために前の画像を次の画像として設定する\n",
    "    prvsImg = nextImg\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python-cvcourse]",
   "language": "python",
   "name": "conda-env-python-cvcourse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
